{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e41d7987",
   "metadata": {},
   "source": [
    "# 2 — Data Preprocessing Pipeline\n",
    "## Next Day Wildfire Spread — TFRecord → Normalised Tensors\n",
    "\n",
    "This notebook documents the data preparation pipeline:\n",
    "\n",
    "1. **Download** — Kaggle API fetches TFRecord shards from `fantineh/next-day-wildfire-spread`\n",
    "2. **Parse** — TFRecords are decoded into 64×64 numpy arrays (12 input channels + 1 target)\n",
    "3. **Filter** — Samples with no fire pixels in the target are discarded\n",
    "4. **NaN handling** — Missing values are replaced with 0\n",
    "5. **Normalise** — Channel-wise z-score normalisation (skip `prev_fire_mask`)\n",
    "6. **Augment** — Random flips and 90° rotations (training only)\n",
    "7. **Save** — Split files `train.npz`, `val.npz`, `test.npz` + `metadata.json`\n",
    "\n",
    "The command-line script `download_data.py` automates steps 1–4 and 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbeac45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "# ── Charger la config générée par 00_Setup.ipynb ──────────────────────────────\n",
    "_cfg_path = Path().resolve() / \"setup_config.json\"\n",
    "if not _cfg_path.exists():\n",
    "    raise FileNotFoundError(\n",
    "        \"setup_config.json introuvable.\\n\"\n",
    "        \"→ Lance d'abord le notebook 00_Setup.ipynb\"\n",
    "    )\n",
    "cfg = json.load(open(_cfg_path))\n",
    "\n",
    "PROCESSED_DIR    = Path(cfg[\"PROCESSED_DIR\"])\n",
    "FIGURES_DIR      = Path(cfg[\"FIGURES_DIR\"])\n",
    "MODELS_DIR       = Path(cfg[\"MODELS_DIR\"])\n",
    "FEATURE_CHANNELS = cfg[\"FEATURE_CHANNELS\"]\n",
    "N_INPUT_CHANNELS = cfg[\"N_INPUT_CHANNELS\"]\n",
    "CH               = cfg[\"CH\"]\n",
    "GRID_SIZE        = cfg[\"GRID_SIZE\"]\n",
    "norm_stats       = cfg[\"norm_stats\"]\n",
    "\n",
    "sns.set_theme(style='whitegrid', font_scale=1.1)\n",
    "%matplotlib inline\n",
    "\n",
    "print(f\"Config chargée depuis : {_cfg_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ecfc5a",
   "metadata": {},
   "source": [
    "## 2.1 Download & Convert (if needed)\n",
    "\n",
    "If the processed `.npz` files do not exist, run:\n",
    "```bash\n",
    "python download_data.py\n",
    "```\n",
    "This downloads ~2 GB of TFRecord shards from Kaggle and converts them to numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7dc5712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if data exists\n",
    "for split in ['train', 'val', 'test']:\n",
    "    p = Path(PROCESSED_DIR) / f'{split}.npz'\n",
    "    if p.exists():\n",
    "        d = np.load(p)\n",
    "        print(f'{split}: X={d[\"X\"].shape}, Y={d[\"Y\"].shape}, size={p.stat().st_size / 1e6:.1f} MB')\n",
    "    else:\n",
    "        print(f'{split}: NOT FOUND — run `python download_data.py`')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0ab2f2",
   "metadata": {},
   "source": [
    "## 2.2 Normalisation Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92261b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Default normalisation statistics (channel-wise):\\n')\n",
    "print(f'{\"Channel\":>18s}  {\"Mean\":>10s}  {\"Std\":>10s}')\n",
    "print('-' * 42)\n",
    "for name in FEATURE_CHANNELS:\n",
    "    if name in DEFAULT_STATS:\n",
    "        m, s = DEFAULT_STATS[name]\n",
    "        print(f'{name:>18s}  {m:10.4f}  {s:10.4f}')\n",
    "    else:\n",
    "        print(f'{name:>18s}  (not normalised)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d036bb5",
   "metadata": {},
   "source": [
    "## 2.3 Normalisation Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fdd362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a few training samples\n",
    "train_path = Path(PROCESSED_DIR) / 'train.npz'\n",
    "if train_path.exists():\n",
    "    data = np.load(train_path)\n",
    "    X_raw = data['X'][:20]  # first 20 samples\n",
    "    Y_raw = data['Y'][:20]\n",
    "    \n",
    "    # Normalise\n",
    "    X_norm = np.stack([normalise(x) for x in X_raw])\n",
    "    \n",
    "    # Compare raw vs normalised for a sample\n",
    "    idx = 0\n",
    "    fig, axes = plt.subplots(2, 4, figsize=(18, 8))\n",
    "    show_channels = ['elevation', 'wind_speed', 'ndvi', 'humidity']\n",
    "    \n",
    "    for j, ch_name in enumerate(show_channels):\n",
    "        ci = CH[ch_name]\n",
    "        axes[0, j].imshow(X_raw[idx, ci], cmap='viridis')\n",
    "        axes[0, j].set_title(f'{ch_name} (raw)', fontweight='bold')\n",
    "        axes[0, j].axis('off')\n",
    "        \n",
    "        axes[1, j].imshow(X_norm[idx, ci], cmap='viridis')\n",
    "        axes[1, j].set_title(f'{ch_name} (normalised)', fontweight='bold')\n",
    "        axes[1, j].axis('off')\n",
    "    \n",
    "    plt.suptitle('Raw vs Normalised Features', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../results/figures/preprocessing_normalisation.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "else:\n",
    "    print('No training data. Run download_data.py first.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c570530",
   "metadata": {},
   "source": [
    "## 2.4 Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb30417",
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_path.exists():\n",
    "    x_sample = X_norm[0]  # (C, H, W)\n",
    "    y_sample = Y_raw[0]   # (1, H, W)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 4, figsize=(18, 8))\n",
    "    \n",
    "    for j in range(4):\n",
    "        xa, ya = augment_sample(x_sample, y_sample, seed=j)\n",
    "        axes[0, j].imshow(xa[CH['elevation']], cmap='terrain')\n",
    "        axes[0, j].set_title(f'Elevation (aug {j})', fontweight='bold')\n",
    "        axes[0, j].axis('off')\n",
    "        \n",
    "        axes[1, j].imshow(ya.squeeze(), cmap='hot', vmin=0, vmax=1)\n",
    "        axes[1, j].set_title(f'FireMask (aug {j})', fontweight='bold')\n",
    "        axes[1, j].axis('off')\n",
    "    \n",
    "    plt.suptitle('Augmented Views of the Same Sample', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../results/figures/preprocessing_augmentations.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2099aacb",
   "metadata": {},
   "source": [
    "## 2.5 NaN Handling Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e6e760",
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_path.exists():\n",
    "    full_train = np.load(train_path)\n",
    "    X_all = full_train['X']\n",
    "    \n",
    "    print('NaN fraction per channel (should be 0 after processing):\\n')\n",
    "    for i, name in enumerate(FEATURE_CHANNELS):\n",
    "        nan_frac = np.isnan(X_all[:, i]).mean()\n",
    "        status = 'OK' if nan_frac == 0 else f'WARNING: {nan_frac:.4%}'\n",
    "        print(f'  {name:>18s}: {status}')\n",
    "    \n",
    "    print(f'\\nTarget NaN: {np.isnan(full_train[\"Y\"]).mean():.4%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a7e37f",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "The preprocessing pipeline converts raw TFRecord satellite observations into normalised 64×64 tensors:\n",
    "\n",
    "- **12 input channels**, z-score normalised (except binary `prev_fire_mask`)\n",
    "- **1 binary target** (next-day fire mask)\n",
    "- **Geographic pre-split**: train / val / test — no spatial leakage\n",
    "- **Augmentation**: random flips & rotations applied on-the-fly during training\n",
    "- **NaN → 0**: missing values replaced to ensure numerical stability"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
